{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import natsort\n",
    "\n",
    "import os\n",
    "import math\n",
    "import multiprocessing\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graphs(result_folders, now):\n",
    "\n",
    "    print(\"Beginning graphing of result files: {}\".format(result_folders))\n",
    "\n",
    "    if not config[\"processed-result-dir\"]:\n",
    "        config[\"processed-result-dir\"] = prepare_results(result_folders, now)\n",
    "\n",
    "    for graph_title in __results[\"graph-configurations\"]:\n",
    "        print(\"Graphing configuration: {}\".format(graph_title))\n",
    "        folders_for_comparison = []\n",
    "        configurations = []\n",
    "        for configuration in __results[\"graph-configurations\"][graph_title]:\n",
    "            for folder in config[\"processed-result-dir\"]:\n",
    "                config_name = folder.split(\"/\")[-1][:-20]\n",
    "                if configuration == config_name:\n",
    "                    folders_for_comparison.append(folder)\n",
    "                    configurations.append(configuration)\n",
    "                    \n",
    "        print(\"Now going to the graphing stage\")\n",
    "\n",
    "        for graph in __results[\"graphs\"]:\n",
    "            if graph in [\"PDR-SCI\", \"PDR-TB\", \"IPG\"]:\n",
    "                distance_graph(folders_for_comparison, graph, graph_title, configurations, now)\n",
    "            elif graph == \"CBR\":\n",
    "                cbr_graph(folders_for_comparison, graph, graph_title, configurations, now)\n",
    "            elif graph == \"Errors\":\n",
    "                errors_dist(folders_for_comparison, graph, graph_title, configurations, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_results(result_folders, now):\n",
    "\n",
    "    num_processes = config[\"parallel_processes\"]\n",
    "    if num_processes > multiprocessing.cpu_count():\n",
    "        print(\"Too many processes, going to revert to total - 1\")\n",
    "        num_processes = multiprocessing.cpu_count() - 1\n",
    "\n",
    "    processed_results = []\n",
    "    for folder in result_folders:\n",
    "        config_name = folder.split(\"/\")[-1][:-20]\n",
    "        print(\"Results for config: {}\".format(config_name))\n",
    "        folder_results = []\n",
    "        files = natsort.natsorted(os.listdir(folder))\n",
    "\n",
    "        filtered_files = []\n",
    "        for i in range(len(files)):\n",
    "            # Ensures we don't load files passed by accident\n",
    "            if \".csv\" in files[i]:\n",
    "                filtered_files.append(\"{}/{}\".format(folder, files[i]))\n",
    "\n",
    "        i = 0\n",
    "        while i < len(filtered_files):\n",
    "            if len(filtered_files) < num_processes:\n",
    "                num_processes = len(filtered_files)\n",
    "            pool = multiprocessing.Pool(processes=num_processes)\n",
    "\n",
    "            folder_results.append(pool.starmap(generate_results, zip(filtered_files[i: i + num_processes])))\n",
    "\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "\n",
    "            i += num_processes\n",
    "\n",
    "        folder_results = [y for x in folder_results for y in x]\n",
    "        # Go through each of the available stats and write them out to a csv file.\n",
    "        output_csv_dir = \"{}/data/processed_data/{}/{}-{}\".format(\"/hdd/results-analysis\", experiment_type,\n",
    "                                                                  config_name, now)\n",
    "\n",
    "        os.makedirs(output_csv_dir, exist_ok=True)\n",
    "\n",
    "        # Shortcut ensures we get the stats from the parsed results\n",
    "        for stat in folder_results[0]:\n",
    "            if stat == \"CBR\":\n",
    "                across_run_results(folder_results, stat, output_csv_dir, \"Time\")\n",
    "            else:\n",
    "                across_run_results(folder_results, stat, output_csv_dir, \"Distance\")\n",
    "\n",
    "        processed_results.append(output_csv_dir)\n",
    "\n",
    "    print(\"Folders processed: {}\".format(processed_results))\n",
    "    return processed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(output_csv):\n",
    "\n",
    "    print(\"Generating results for file: {}\".format(output_csv))\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    pdr_sci_agg = pd.DataFrame()\n",
    "    pdr_tb_agg = pd.DataFrame()\n",
    "    ipg_agg = pd.DataFrame()\n",
    "    cbr_agg = pd.DataFrame()\n",
    "    unsensed_errors = pd.DataFrame()\n",
    "    hd_errors = pd.DataFrame()\n",
    "    prop_errors = pd.DataFrame()\n",
    "    interference_errors = pd.DataFrame()\n",
    "    \n",
    "    error_dfs = {}\n",
    "    # Need a new for loop through all the errors and adding them as a stat distance\n",
    "    for error in __results[\"errors\"]:\n",
    "        error_dfs[error] = pd.DataFrame()\n",
    "\n",
    "    for chunk in pd.read_csv(output_csv, chunksize=10 ** 6):\n",
    "\n",
    "        # SCI PDR calculation\n",
    "        pdr_sci_agg = stat_distance(pdr_sci_agg, chunk, \"sciDecoded\", \"txRxDistanceSCI\", True)\n",
    "\n",
    "        # TB PDR calculation\n",
    "        pdr_tb_agg = stat_distance(pdr_tb_agg, chunk, \"tbDecoded\", \"txRxDistanceTB\", True)\n",
    "\n",
    "        # IPG calculation\n",
    "        ipg_agg = stat_distance(ipg_agg, chunk, \"interPacketDelay\", \"txRxDistanceTB\", False)\n",
    "\n",
    "        # CBR calculation doesn't aggregate the same way as the above so dealt with separately\n",
    "        cbr_df = chunk[chunk[\"cbr\"].notnull()]\n",
    "        cbr_df = cbr_df[[\"Time\", \"cbr\"]]\n",
    "        cbr_df = cbr_df.groupby(\"Time\").agg({\"cbr\": [np.mean, np.std, \"count\"]})\n",
    "        cbr_df.columns = cbr_df.columns.droplevel()\n",
    "        cbr_df = cbr_df.apply(lambda x: x * 100, axis=1)\n",
    "\n",
    "        if cbr_agg.empty:\n",
    "            cbr_agg = cbr_df\n",
    "        else:\n",
    "            # combine_chunks\n",
    "            cbr_agg = cbr_agg.append(cbr_df)\n",
    "            \n",
    "        chunk = chunk[chunk[\"tbReceived\"] != -1]\n",
    "        for error in error_dfs:\n",
    "            if \"sci\" in error[0:3]:\n",
    "                error_dfs[error] = stat_distance(error_dfs[error], chunk, error, \"txRxDistanceSCI\", True)\n",
    "            else:\n",
    "                error_dfs[error] = stat_distance(error_dfs[error], chunk, error, \"txRxDistanceTB\", True)\n",
    "\n",
    "    results[\"PDR-SCI\"] = pdr_sci_agg\n",
    "    results[\"PDR-TB\"] = pdr_tb_agg\n",
    "    results[\"IPG\"] = ipg_agg\n",
    "    results[\"CBR\"] = cbr_agg\n",
    "    \n",
    "    \n",
    "    for error in __results[\"unsensed_errors\"]:\n",
    "        if unsensed_errors.empty:\n",
    "            unsensed_errors = error_dfs[error]\n",
    "        else:\n",
    "            # combine_chunks\n",
    "            unsensed_errors = pd.merge(unsensed_errors, error_dfs[error], on=\"Distance\", how='outer')\n",
    "            unsensed_errors = unsensed_errors.apply(combine_line, axis=1, result_type='expand')\n",
    "            unsensed_errors = unsensed_errors.rename({0: \"mean\", 1: \"count\"}, axis='columns')\n",
    "            \n",
    "    for error in __results[\"hd_errors\"]:\n",
    "        if hd_errors.empty:\n",
    "            hd_errors = error_dfs[error]\n",
    "        else:\n",
    "            # combine_chunks\n",
    "            hd_errors = pd.merge(hd_errors, error_dfs[error], on=\"Distance\", how='outer')\n",
    "            hd_errors = hd_errors.apply(combine_line, axis=1, result_type='expand')\n",
    "            hd_errors = hd_errors.rename({0: \"mean\", 1: \"count\"}, axis='columns')\n",
    "            \n",
    "    for error in __results[\"prop_errors\"]:\n",
    "        if prop_errors.empty:\n",
    "            prop_errors = error_dfs[error]\n",
    "        else:\n",
    "            # combine_chunks\n",
    "            prop_errors = pd.merge(prop_errors, error_dfs[error], on=\"Distance\", how='outer')\n",
    "            prop_errors = prop_errors.apply(combine_line, axis=1, result_type='expand')\n",
    "            prop_errors = prop_errors.rename({0: \"mean\", 1: \"count\"}, axis='columns')\n",
    "        \n",
    "    for error in __results[\"interference_errors\"]:\n",
    "        if interference_errors.empty:\n",
    "            interference_errors = error_dfs[error]\n",
    "        else:\n",
    "            # combine_chunks\n",
    "            interference_errors = pd.merge(interference_errors, error_dfs[error], on=\"Distance\", how='outer')\n",
    "            interference_errors = interference_errors.apply(combine_line, axis=1, result_type='expand')\n",
    "            interference_errors = interference_errors.rename({0: \"mean\", 1: \"count\"}, axis='columns')\n",
    "    \n",
    "    results[\"unsensed_errors\"] = unsensed_errors\n",
    "    results[\"hd_errors\"] = hd_errors\n",
    "    results[\"prop_errors\"] = prop_errors\n",
    "    results[\"interference_errors\"] = interference_errors\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_distance(agg_df, df, stat, distance, percentage):\n",
    "\n",
    "    # Reduce the size of the DF to what we're interested in.\n",
    "    distance_df = df[df[stat].notnull()]\n",
    "    distance_df = df[(df[\"posX\"] > 1500) & (df[\"posX\"] < 3500)]\n",
    "    distance_df = distance_df[[\"Time\", \"NodeID\", stat, distance]]\n",
    "    distance_df = distance_df[distance_df[stat] > -1]\n",
    "    distance_df = distance_df.rename(columns={\"Time\": \"Time\", \"NodeID\": \"NodeID\", stat: stat, distance: \"Distance\"})\n",
    "\n",
    "    # Only interested in max 500m simply as it's not all that relevant to go further.\n",
    "    # Note that going to the max distance of the file can cause issues with how they are parsed.\n",
    "    max_distance = min(525, distance_df[\"Distance\"].max())\n",
    "\n",
    "    # Get the mean, std, count for each distance\n",
    "    distance_df = distance_df.groupby(\n",
    "        pd.cut(distance_df[\"Distance\"], np.arange(0, max_distance, 25))).agg(\n",
    "        {stat: [np.mean, \"count\"]})\n",
    "\n",
    "    # Remove over head column\n",
    "    distance_df.columns = distance_df.columns.droplevel()\n",
    "\n",
    "    if percentage:\n",
    "        distance_df = distance_df.apply(lambda x: x * 100, axis=1)\n",
    "\n",
    "    if agg_df.empty:\n",
    "        agg_df = distance_df\n",
    "    else:\n",
    "        # combine_chunks\n",
    "        agg_df = pd.merge(agg_df, distance_df, on=\"Distance\", how='outer')\n",
    "        agg_df = agg_df.apply(combine_line, axis=1, result_type='expand')\n",
    "        agg_df = agg_df.rename({0: \"mean\", 1: \"count\"}, axis='columns')\n",
    "\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_line(line):\n",
    "    mean_a = line[\"mean_x\"]\n",
    "    count_a = line[\"count_x\"]\n",
    "\n",
    "    mean_b = line[\"mean_y\"]\n",
    "    count_b = line[\"count_y\"]\n",
    "\n",
    "    if np.isnan(mean_a) and np.isnan(mean_b):\n",
    "        return [mean_a, count_a]\n",
    "    elif np.isnan(mean_a) and not np.isnan(mean_b):\n",
    "        return [mean_b, count_b]\n",
    "    elif np.isnan(mean_b) and not np.isnan(mean_a):\n",
    "        return [mean_a, count_a]\n",
    "    else:\n",
    "        ex_a = mean_a * count_a\n",
    "        ex_b = mean_b * count_b\n",
    "\n",
    "        tx = ex_a + ex_b\n",
    "        tn = count_a + count_b\n",
    "\n",
    "        overall_mean = tx / tn\n",
    "        overall_count = tn\n",
    "\n",
    "        return [overall_mean, overall_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def across_run_results(results, stat, output_csv_dir, merge_col):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    print(\"Statistic of interest: {}\".format(stat))\n",
    "    for i in range(len(results)):\n",
    "        if df.empty:\n",
    "            df = results[i][stat]\n",
    "        else:\n",
    "            df = pd.merge(df, results[i][stat], how='outer', on=merge_col,\n",
    "                          suffixes=(i, i + 1),\n",
    "                          copy=True, indicator=False)\n",
    "\n",
    "    mean_cols = df.filter(regex='mean').columns\n",
    "\n",
    "    n = len(mean_cols) - 1\n",
    "    t_value = t.ppf(p, n)\n",
    "\n",
    "    df = df.apply(combine_runs, axis=1, result_type='expand', args=(mean_cols, t_value,))\n",
    "    df = df.rename({0: \"Mean\", 1: \"Confidence-Interval\"}, axis='columns')\n",
    "    df.to_csv(\"{}/{}.csv\".format(output_csv_dir, stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_runs(line, mean_cols, t_value):\n",
    "    means = []\n",
    "    for mean in mean_cols:\n",
    "        means.append(line[mean])\n",
    "\n",
    "    n = len(means)\n",
    "\n",
    "    # Average Across runs\n",
    "    xBar = sum(means) / n\n",
    "\n",
    "    # Deviation between runs and average\n",
    "    deviation = []\n",
    "    for mean in means:\n",
    "        deviation.append((mean - xBar) ** 2)\n",
    "    s2 = sum(deviation) / (n - 1)\n",
    "\n",
    "    # Confidence interval\n",
    "    ci = t_value * math.sqrt(s2 / n)\n",
    "\n",
    "    return [xBar, ci]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graphing utilities\n",
    "\n",
    "def distance_graph(folders, graph, comparison, configurations, now):\n",
    "    means = []\n",
    "    cis = []\n",
    "    distances = []\n",
    "    for folder, config in zip(folders, configurations):\n",
    "        df = pd.read_csv(\"{}/{}.csv\".format(folder, graph))\n",
    "        means.append(list(df[\"Mean\"]))\n",
    "        if confidence_intervals:\n",
    "            cis.append(list(df[\"Confidence-Interval\"]))\n",
    "        distances = (list(range(0, df.shape[0] * 25, 25)))\n",
    "\n",
    "    if graph in [\"PDR-SCI\", \"PDR-TB\"]:\n",
    "        dist_graph(means, distances, configurations,\n",
    "                    \"{}-{}\".format(comparison, graph), ylabel=\"Packet Delivery Rate %\", now=now,\n",
    "                    confidence_intervals=cis, show=False, store=True, percentage=True)\n",
    "    elif graph == \"IPG\":\n",
    "        dist_graph(means, distances, configurations,\n",
    "                    \"{}-{}\".format(comparison, graph), ylabel=\"Inter-Packet Gap (ms)\", now=now,\n",
    "                    legend_pos=\"upper left\", confidence_intervals=cis, show=False, store=True)\n",
    "\n",
    "def cbr_graph(folders, graph, comparison, configurations, now):\n",
    "    # Might change this to time based graph but CBR is fine for now\n",
    "    times = []\n",
    "    cbr = []\n",
    "    cis = []\n",
    "    for folder, config in zip(folders, configurations):\n",
    "        df = pd.read_csv(\"{}/CBR.csv\".format(folder))\n",
    "        times.append(list(df[\"Time\"]))\n",
    "        cbr.append(list(df[\"Mean\"]))\n",
    "        if confidence_intervals:\n",
    "            cis.append(list(df[\"Confidence-Interval\"]))\n",
    "\n",
    "    cbr_plot(cbr, times, \"{}-{}\".format(comparison, graph), configurations, now=now,\n",
    "             confidence_intervals=cis, show=False, store=True)\n",
    "\n",
    "def dist_graph(means, distances, labels, plot_name, ylabel, now, legend_pos=\"lower left\",\n",
    "               confidence_intervals=None, show=True, store=False, percentage=False):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for i in range(len(means)):\n",
    "        if confidence_intervals:\n",
    "            ax.errorbar(distances, means[i], yerr=confidence_intervals[i], label=labels[i])\n",
    "        else:\n",
    "            ax.plot(distances, means[i], label=labels[i])\n",
    "\n",
    "    ax.set(xlabel='Distance (m)', ylabel=ylabel)\n",
    "    ax.legend(loc=legend_pos)\n",
    "    ax.tick_params(direction='in')\n",
    "\n",
    "    ax.set_xlim([0, (max(distances) + 1)])\n",
    "    plt.xticks(np.arange(0, (max(distances) + 1), step=50))\n",
    "\n",
    "    if percentage:\n",
    "        ax.set_ylim([0, 100])\n",
    "        plt.yticks(np.arange(0, 101, step=10))\n",
    "\n",
    "    if show:\n",
    "        fig.show()\n",
    "\n",
    "    if store:\n",
    "        fig.savefig(\"{}/{}-{}.png\".format(figure_store, plot_name, now), dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "def cbr_plot(cbr, times, plot_name, labels, now, confidence_intervals=None, show=True, store=False):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for i in range(len(cbr)):\n",
    "        if confidence_intervals:\n",
    "            ax.errorbar(times[i], cbr[i], yerr=confidence_intervals[i], label=labels[i])\n",
    "        else:\n",
    "            ax.plot(times[i], cbr[i], label=labels[i])\n",
    "\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set(xlabel='Time (s)', ylabel='Channel Busy Ratio %')\n",
    "    ax.tick_params(direction='in')\n",
    "\n",
    "    ax.set_ylim([0, 100])\n",
    "    plt.yticks(np.arange(0, 101, step=10))\n",
    "\n",
    "    if show:\n",
    "        fig.show()\n",
    "\n",
    "    if store:\n",
    "        fig.savefig(\"{}/{}-{}.png\".format(figure_store, plot_name, now), dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_dist(folders, graph, comparison, configurations, now):\n",
    "    # TODO: Update to allow such graphing to be automatically configured.\n",
    "        \n",
    "    means = []\n",
    "    cis = []\n",
    "    distances = []\n",
    "    labels = []    \n",
    "    \n",
    "    for folder, config in zip(folders, configurations):\n",
    "        for error in [\"unsensed_errors\", \"hd_errors\", \"prop_errors\", \"interference_errors\"]:\n",
    "            df = pd.read_csv(\"{}/{}.csv\".format(folder, error))\n",
    "            means.append(list(df[\"Mean\"]))\n",
    "            if confidence_intervals:\n",
    "                cis.append(list(df[\"Confidence-Interval\"]))\n",
    "            distances = (list(range(0, df.shape[0] * 25, 25)))\n",
    "            labels.append(\"{}-{}\".format(config, error))\n",
    "        \n",
    "\n",
    "    \n",
    "    dist_graph(means, distances, labels,\n",
    "               \"{}-{}\".format(comparison, graph), ylabel=\"Error Probability %\", now=now,\n",
    "               confidence_intervals=cis, show=False, store=True, percentage=True, legend_pos=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_markers = False\n",
    "use_line_types = False\n",
    "image_format = \"png\"\n",
    "figure_store = \"/hdd/results-analysis/data/figures\"\n",
    "markers = [\".\", \"o\", \"v\", \"^\", \"<\", \">\", \"1\", \"2\", \"3\", \"4\", \"8\", \"s\", \"p\", \"P\", \"*\", \"h\", \"H\", \"+\",\n",
    "                    \"x\", \"X\", \"D\", \"d\", \"|\", \"_\", 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "    \n",
    "config_path = \"/hdd/results-analysis/configs/mcs7.json\"\n",
    "\n",
    "experiment_type = \"mcs7\"\n",
    "with open(config_path) as json_file:\n",
    "    config = json.load(json_file)[experiment_type]\n",
    "    \n",
    "    __results = config[\"results\"]\n",
    "    \n",
    "    p = __results[\"confidence-interval\"]\n",
    "    \n",
    "    confidence_intervals = __results[\"graph-confidence-interval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning graphing of result files: ['/hdd/results-analysis/data/parsed_data/mcs7/MCS7-1vpm-20dbm-2020-04-14-00_06_11']\n",
      "Results for config: MCS7-1vpm-20dbm\n",
      "Generating results for file: /hdd/results-analysis/data/parsed_data/mcs7/MCS7-1vpm-20dbm-2020-04-14-00_06_11/run-1.csv\n",
      "Generating results for file: /hdd/results-analysis/data/parsed_data/mcs7/MCS7-1vpm-20dbm-2020-04-14-00_06_11/run-2.csv\n",
      "Generating results for file: /hdd/results-analysis/data/parsed_data/mcs7/MCS7-1vpm-20dbm-2020-04-14-00_06_11/run-3.csv\n",
      "Generating results for file: /hdd/results-analysis/data/parsed_data/mcs7/MCS7-1vpm-20dbm-2020-04-14-00_06_11/run-4.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot perform 'rand_' with a dtyped [float64] array and scalar of type [bool]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/brianmccarthy/anaconda3/envs/results-analysis/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\", line 273, in na_logical_op\n    result = op(x, y)\n  File \"/home/brianmccarthy/anaconda3/envs/results-analysis/lib/python3.8/site-packages/pandas/core/ops/roperator.py\", line 52, in rand_\n    return operator.and_(right, left)\nTypeError: ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brianmccarthy/anaconda3/envs/results-analysis/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\", line 287, in na_logical_op\n    result = libops.scalar_binop(x, y, op)\n  File \"pandas/_libs/ops.pyx\", line 169, in pandas._libs.ops.scalar_binop\nValueError: Buffer dtype mismatch, expected 'Python object' but got 'double'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brianmccarthy/anaconda3/envs/results-analysis/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/brianmccarthy/anaconda3/envs/results-analysis/lib/python3.8/multiprocessing/pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"<ipython-input-4-5b1e8145ec72>\", line 24, in generate_results\n    pdr_sci_agg = stat_distance(pdr_sci_agg, chunk, \"sciDecoded\", \"txRxDistanceSCI\", True)\n  File \"<ipython-input-14-8f05570a0c06>\", line 5, in stat_distance\n    distance_df = df[df[\"posX\"] > 1500 & df[\"posX\"] < 3500]\n  File \"/home/brianmccarthy/anaconda3/envs/results-analysis/lib/python3.8/site-packages/pandas/core/ops/common.py\", line 64, in new_method\n    return method(self, other)\n  File \"/home/brianmccarthy/anaconda3/envs/results-analysis/lib/python3.8/site-packages/pandas/core/ops/__init__.py\", line 549, in wrapper\n    res_values = logical_op(lvalues, rvalues, op)\n  File \"/home/brianmccarthy/anaconda3/envs/results-analysis/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\", line 365, in logical_op\n    res_values = na_logical_op(lvalues, rvalues, op)\n  File \"/home/brianmccarthy/anaconda3/envs/results-analysis/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\", line 296, in na_logical_op\n    raise TypeError(\nTypeError: Cannot perform 'rand_' with a dtyped [float64] array and scalar of type [bool]\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2b6ace4d38c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"parsed-result-dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"00_00_00-01-01-2020\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-a83bcb13060a>\u001b[0m in \u001b[0;36mgenerate_graphs\u001b[0;34m(result_folders, now)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"processed-result-dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"processed-result-dir\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_folders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgraph_title\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"graph-configurations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c44e965a5200>\u001b[0m in \u001b[0;36mprepare_results\u001b[0;34m(result_folders, now)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_processes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mfolder_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_processes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/results-analysis/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         '''\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m~/anaconda3/envs/results-analysis/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot perform 'rand_' with a dtyped [float64] array and scalar of type [bool]"
     ]
    }
   ],
   "source": [
    "generate_graphs(config[\"parsed-result-dir\"], \"00_00_00-01-01-2020\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
