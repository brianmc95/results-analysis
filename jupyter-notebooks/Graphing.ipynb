{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import math\n",
    "import multiprocessing\n",
    "import json\n",
    "import re\n",
    "\n",
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_markers = False\n",
    "experiment_type = \"cv2x\"\n",
    "\n",
    "use_line_types = False\n",
    "image_format = \"png\"\n",
    "figure_store = \"../data/figures/\"\n",
    "\n",
    "markers = [\".\", \"o\", \"v\", \"^\", \"<\", \">\", \"1\", \"2\", \"3\", \"4\", \"8\", \"s\", \"p\", \"P\", \"*\", \"h\", \"H\", \"+\",\n",
    "           \"x\", \"X\", \"D\", \"d\", \"|\", \"_\", 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "\n",
    "overall_now=\"12:00:00\"\n",
    "confidence_intervals = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runner for overall job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graphs(result_folders, now):\n",
    "\n",
    "    print(\"Beginning graphing of result file: {}\".format(result_folders))\n",
    "\n",
    "    if not config[\"processed-result-dir\"]:\n",
    "        config[\"processed-result-dir\"] = prepare_results(result_folders, now)\n",
    "\n",
    "    for graph_title in results[\"graph-configurations\"]:\n",
    "        print(\"Graphing configuration: {}\".format(graph_title))\n",
    "        folders_for_comparison = []\n",
    "        configurations = []\n",
    "        for configuration in results[\"graph-configurations\"][graph_title]:\n",
    "            for folder in config[\"processed-result-dir\"]:\n",
    "                config_name = folder.split(\"/\")[-1][:-20]\n",
    "                if configuration == config_name:\n",
    "                    folders_for_comparison.append(folder)\n",
    "                    configurations.append(configuration)\n",
    "\n",
    "        for graph in results[\"graphs\"]:\n",
    "            if graph in [\"PDR-SCI\", \"PDR-TB\", \"IPG\"]:\n",
    "                distance_graph(folders_for_comparison, graph, graph_title, configurations, now)\n",
    "            elif graph == \"CBR\":\n",
    "                cbr_graph(folders_for_comparison, graph, graph_title, configurations, now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Preparation stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_results(result_folders, now):\n",
    "\n",
    "    num_processes = config[\"parallel_processes\"]\n",
    "    if num_processes > multiprocessing.cpu_count():\n",
    "        print(\"Too many processes, going to revert to total - 1\")\n",
    "        num_processes = multiprocessing.cpu_count() - 1\n",
    "\n",
    "    processed_results = []\n",
    "    for folder in result_folders:\n",
    "        config_name = folder.split(\"/\")[-1]\n",
    "        print(\"Results for config: {}\".format(config_name))\n",
    "        folder_results = []\n",
    "        files = natsort.natsorted(os.listdir(folder))\n",
    "        \n",
    "        filtered_files = []\n",
    "        for i in range(len(files)):\n",
    "            if \".csv\" in files[i]:\n",
    "                filtered_files.append(\"{}/{}\".format(folder, files[i]))\n",
    "\n",
    "        i = 0\n",
    "        while i < len(filtered_files):\n",
    "            if len(filtered_files) < num_processes:\n",
    "                num_processes = len(filtered_files)\n",
    "            pool = multiprocessing.Pool(processes=num_processes)\n",
    "\n",
    "            folder_results.append(pool.starmap(generate_results, zip(filtered_files[i: i + num_processes])))\n",
    "\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "\n",
    "            i += num_processes\n",
    "\n",
    "        folder_results = [y for x in folder_results for y in x]\n",
    "        # Go through each of the available stats and write them out to a csv file.\n",
    "        output_csv_dir = \"../data/processed_data/{}/{}-{}\".format(experiment_type,\n",
    "                                                                  config_name, now)\n",
    "\n",
    "        os.makedirs(output_csv_dir, exist_ok=True)\n",
    "\n",
    "        # Shortcut ensures we get the stats from the parsed results\n",
    "        for stat in folder_results[0]:\n",
    "            if \"SCI\" in stat:\n",
    "                across_run_results(folder_results, stat, output_csv_dir, \"txRxDistanceSCI\")\n",
    "            elif stat == \"CBR\":\n",
    "                across_run_results(folder_results, stat, output_csv_dir, \"Time\")\n",
    "            else:\n",
    "                across_run_results(folder_results, stat, output_csv_dir, \"txRxDistanceTB\")\n",
    "\n",
    "        processed_results.append(output_csv_dir)\n",
    "    return processed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(output_csv):\n",
    "\n",
    "    print(\"Generating results for file: {}\".format(output_csv))\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    pdr_sci_agg = pd.DataFrame()\n",
    "    pdr_tb_agg = pd.DataFrame()\n",
    "    ipg_agg = pd.DataFrame()\n",
    "    cbr_agg = pd.DataFrame()\n",
    "\n",
    "    for chunk in pd.read_csv(output_csv, chunksize=10 ** 6):\n",
    "\n",
    "        # SCI PDR calculation\n",
    "        pdr_sci_agg = stat_distance(pdr_sci_agg, chunk, \"sciDecoded\", \"txRxDistanceSCI\", True)\n",
    "\n",
    "        # TB PDR calculation\n",
    "        pdr_tb_agg = stat_distance(pdr_tb_agg, chunk, \"tbDecoded\", \"txRxDistanceTB\", True)\n",
    "\n",
    "        # IPG calculation\n",
    "        ipg_agg = stat_distance(ipg_agg, chunk, \"interPacketDelay\", \"txRxDistanceTB\", False)\n",
    "\n",
    "        # CBR calculation doesn't aggregate the same way as the above so dealt with separately\n",
    "        cbr_df = chunk[chunk[\"cbr\"].notnull()]\n",
    "        cbr_df = cbr_df[[\"Time\", \"cbr\"]]\n",
    "        cbr_df = cbr_df.groupby(\"Time\").agg({\"cbr\": [np.mean, np.std, \"count\"]})\n",
    "        cbr_df.columns = cbr_df.columns.droplevel()\n",
    "        cbr_df = cbr_df.apply(lambda x: x * 100, axis=1)\n",
    "\n",
    "        if cbr_agg.empty:\n",
    "            cbr_agg = cbr_df\n",
    "        else:\n",
    "            # combine_chunks\n",
    "            cbr_agg = cbr_agg.append(cbr_df)\n",
    "\n",
    "    results[\"PDR-SCI\"] = pdr_sci_agg\n",
    "    results[\"PDR-TB\"] = pdr_tb_agg\n",
    "    results[\"IPG\"] = ipg_agg\n",
    "    results[\"CBR\"] = cbr_agg\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_distance(agg_df, df, stat, distance, percentage):\n",
    "\n",
    "    # Reduce the size of the DF to what we're interested in.\n",
    "    distance_df = df[df[stat].notnull()]\n",
    "    distance_df = distance_df[[\"Time\", \"NodeID\", stat, distance, \"posX\"]]\n",
    "    distance_df = distance_df[distance_df[stat] > -1]\n",
    "    distance_df[(distance_df[\"posX\"] > 1500) & (distance_df[\"posX\"] < 3500)]\n",
    "    \n",
    "    # Do a check that the position isn't incorrect.\n",
    "\n",
    "    max_distance = min(510, distance_df[distance].max())\n",
    "\n",
    "    # Get the mean, std, count for each distance\n",
    "    distance_df = distance_df.groupby(\n",
    "        pd.cut(distance_df[distance], np.arange(0, max_distance, 10))).agg(\n",
    "        {stat: [np.mean, \"count\"]})\n",
    "\n",
    "    # Remove over head column\n",
    "    distance_df.columns = distance_df.columns.droplevel()\n",
    "\n",
    "    if percentage:\n",
    "        distance_df = distance_df.apply(lambda x: x * 100, axis=1)\n",
    "\n",
    "    if agg_df.empty:\n",
    "        agg_df = distance_df\n",
    "    else:\n",
    "        # combine_chunks\n",
    "        agg_df = pd.merge(agg_df, distance_df, on=distance, how='outer')\n",
    "        agg_df = agg_df.apply(combine_line, axis=1, result_type='expand')\n",
    "        agg_df = agg_df.rename({0: \"mean\", 1: \"count\"}, axis='columns')\n",
    "\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_line(line):\n",
    "    mean_a = line[\"mean_x\"]\n",
    "    count_a = line[\"count_x\"]\n",
    "\n",
    "    mean_b = line[\"mean_y\"]\n",
    "    count_b = line[\"count_y\"]\n",
    "\n",
    "    if np.isnan(mean_a) and np.isnan(mean_b):\n",
    "        return [mean_a, count_a]\n",
    "    elif np.isnan(mean_a) and not np.isnan(mean_b):\n",
    "        return [mean_b, count_b]\n",
    "    elif np.isnan(mean_b) and not np.isnan(mean_a):\n",
    "        return [mean_a, count_a]\n",
    "    else:\n",
    "        ex_a = mean_a * count_a\n",
    "        ex_b = mean_b * count_b\n",
    "\n",
    "        tx = ex_a + ex_b\n",
    "        tn = count_a + count_b\n",
    "\n",
    "        overall_mean = tx / tn\n",
    "        overall_count = tn\n",
    "\n",
    "        return [overall_mean, overall_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def across_run_results(results, stat, output_csv_dir, merge_col):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    print(\"Statistic of interest: {}\".format(stat))\n",
    "    for i in range(len(results)):\n",
    "        if df.empty:\n",
    "            df = results[i][stat]\n",
    "        else:\n",
    "            df = pd.merge(df, results[i][stat], how='outer', on=merge_col,\n",
    "                          suffixes=(i, i + 1),\n",
    "                          copy=True, indicator=False)\n",
    "\n",
    "    mean_cols = df.filter(regex='mean').columns\n",
    "\n",
    "    n = len(mean_cols) - 1\n",
    "    t_value = t.ppf(p, n)\n",
    "\n",
    "    df = df.apply(combine_runs, axis=1, result_type='expand', args=(mean_cols, t_value,))\n",
    "    df = df.rename({0: \"Mean\", 1: \"Confidence-Interval\"}, axis='columns')\n",
    "    df.to_csv(\"{}/{}.csv\".format(output_csv_dir, stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_runs(line, mean_cols, t_value):\n",
    "    means = []\n",
    "    for mean in mean_cols:\n",
    "        means.append(line[mean])\n",
    "\n",
    "    n = len(means)\n",
    "\n",
    "    # Average Across runs\n",
    "    xBar = sum(means) / n\n",
    "\n",
    "    # Deviation between runs and average\n",
    "    deviation = []\n",
    "    for mean in means:\n",
    "        deviation.append((mean - xBar) ** 2)\n",
    "    s2 = sum(deviation) / (n - 1)\n",
    "\n",
    "    # Confidence interval\n",
    "    ci = t_value * math.sqrt(s2 / n)\n",
    "\n",
    "    return [xBar, ci]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_graph(folders, graph, comparison, configurations, now):\n",
    "    means = []\n",
    "    cis = []\n",
    "    distances = []\n",
    "    for folder, config in zip(folders, configurations):\n",
    "        df = pd.read_csv(\"{}/{}.csv\".format(folder, graph))\n",
    "        means.append(list(df[\"Mean\"]))\n",
    "        if confidence_intervals:\n",
    "            cis.append(list(df[\"Confidence-Interval\"]))\n",
    "        distances = (list(range(0, df.shape[0] * 10, 10)))\n",
    "\n",
    "    if graph in [\"PDR-SCI\", \"PDR-TB\"]:\n",
    "        dist_graph(means, distances, configurations,\n",
    "                   \"{}-{}\".format(comparison, graph), ylabel=\"Packet Delivery Rate %\", now=now,\n",
    "                    confidence_intervals=cis, show=False, store=True)\n",
    "    elif graph == \"IPG\":\n",
    "        dist_graph(means, distances, configurations,\n",
    "                   \"{}-{}\".format(comparison, graph), ylabel=\"Inter-Packet Gap (ms)\", now=now,\n",
    "                   legend_pos=\"upper left\", confidence_intervals=cis, show=False, store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbr_graph(folders, graph, comparison, configurations, now):\n",
    "    # Might change this to time based graph but CBR is fine for now\n",
    "    times = []\n",
    "    cbr = []\n",
    "    cis = []\n",
    "    for folder, config in zip(folders, configurations):\n",
    "        df = pd.read_csv(\"{}/CBR.csv\".format(folder))\n",
    "        times.append(list(df[\"Time\"]))\n",
    "        cbr.append(list(df[\"Mean\"]))\n",
    "        if confidence_intervals:\n",
    "            cis.append(list(df[\"Confidence-Interval\"]))\n",
    "\n",
    "    cbr_plot(cbr, times, \"{}-{}\".format(comparison, graph), configurations, now=now,\n",
    "             confidence_intervals=cis, show=False, store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_graph(means, distances, labels, plot_name, ylabel, now, legend_pos=\"lower left\",\n",
    "               confidence_intervals=None, show=True, store=False):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for i in range(len(means)):\n",
    "        if confidence_intervals:\n",
    "            ax.errorbar(distances, means[i], yerr=confidence_intervals[i], label=labels[i])\n",
    "        else:\n",
    "            ax.plot(distances, means[i], label=labels[i])\n",
    "\n",
    "    ax.set(xlabel='Distance (m)', ylabel=ylabel)\n",
    "    ax.legend(loc=legend_pos)\n",
    "    ax.tick_params(direction='in')\n",
    "\n",
    "    ax.set_xlim([0, (max(distances) + 1)])\n",
    "    plt.xticks(np.arange(0, (max(distances) + 1), step=50))\n",
    "\n",
    "#     fig.suptitle(plot_name, fontsize=12)\n",
    "\n",
    "    if show:\n",
    "        fig.show()\n",
    "\n",
    "    if store:\n",
    "        fig.savefig(\"{}/{}-{}.png\".format(figure_store, plot_name, now), dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbr_plot(cbr, times, plot_name, labels, now, confidence_intervals=None, show=True, store=False):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for i in range(len(cbr)):\n",
    "        if confidence_intervals:\n",
    "            ax.errorbar(times[i], cbr[i], yerr=confidence_intervals[i], label=labels[i])\n",
    "        else:\n",
    "            ax.plot(times[i], cbr[i], label=labels[i])\n",
    "\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set(xlabel='Time (s)', ylabel='Channel Busy Ratio %')\n",
    "    ax.tick_params(direction='in')\n",
    "\n",
    "    ax.set_ylim([0, 100])\n",
    "    plt.yticks(np.arange(0, 101, step=10))\n",
    "\n",
    "#     fig.suptitle(plot_name, fontsize=12)\n",
    "\n",
    "    if show:\n",
    "        fig.show()\n",
    "\n",
    "    if store:\n",
    "        fig.savefig(\"{}/{}-{}.png\".format(figure_store, plot_name, now), dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_dist(distances, decoded, decoded_labels, errors, error_labels, plot_name):\n",
    "    # TODO: Update to allow such graphing to be automatically configured.\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    if use_markers:\n",
    "        for i in range(len(decoded)):\n",
    "            ax.plot(distances, decoded[i], label=decoded_labels[i], marker=markers[i], markevery=3)\n",
    "\n",
    "            for j in range(len(errors[i])):\n",
    "                ax.plot(distances, errors[i][j], label=error_labels[i][j], marker=markers[i + j])\n",
    "\n",
    "    elif use_line_types:\n",
    "        for i in range(len(decoded)):\n",
    "            ax.plot(distances, decoded[i], label=decoded_labels[i])\n",
    "\n",
    "            for j in range(len(errors[i])):\n",
    "                ax.plot(distances, errors[i][j], label=error_labels[i][j])\n",
    "\n",
    "    else:\n",
    "        for i in range(len(decoded)):\n",
    "            ax.plot(distances, decoded[i], label=decoded_labels[i])\n",
    "\n",
    "            for j in range(len(errors[i])):\n",
    "                ax.plot(distances, errors[i][j], label=error_labels[i][j])\n",
    "\n",
    "    ax.legend(loc='center left')\n",
    "\n",
    "    ax.set(xlabel='Distance (m)', ylabel='Packet Delivery Rate (PDR) %')\n",
    "    ax.grid()\n",
    "\n",
    "    ax.set_ylim([0, 1])\n",
    "    plt.yticks(np.arange(0, 1.1, step=.1))\n",
    "\n",
    "    ax.set_xlim([0, (max(distances) + 1)])\n",
    "    plt.xticks(np.arange(0, (max(distances) + 1), step=50))\n",
    "\n",
    "    fig.savefig(\"{}/{}-{}.png\".format(figure_store, plot_name, now), dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/Users/brianmccarthy/git_repos/results-analysis/configs/cv2x.json\"\n",
    "with open(config_file) as config_json:\n",
    "    config = json.load(config_json)[experiment_type]\n",
    "results = config[\"results\"]\n",
    "p = results[\"confidence-interval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_graphs(config[\"parsed-result-dir\"], overall_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed_data/mcs9/9MCS_23dBm_01vpm-2020-02-28-16_48_32/run-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = \"tbDecoded\"\n",
    "distance = \"txRxDistanceTB\"\n",
    "distance_df = df[df[stat].notnull()]\n",
    "distance_df = distance_df[[\"Time\", \"NodeID\", stat, distance, \"posX\", \"posY\"]]\n",
    "distance_df = distance_df[distance_df[stat] > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>NodeID</th>\n",
       "      <th>tbDecoded</th>\n",
       "      <th>txRxDistanceTB</th>\n",
       "      <th>posX</th>\n",
       "      <th>posY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62545</th>\n",
       "      <td>500.126</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1464.395216</td>\n",
       "      <td>1374.509312</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62547</th>\n",
       "      <td>500.126</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1425.415750</td>\n",
       "      <td>1413.488928</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62549</th>\n",
       "      <td>500.126</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1386.937657</td>\n",
       "      <td>1451.967177</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62551</th>\n",
       "      <td>500.126</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1345.814549</td>\n",
       "      <td>1493.090461</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62553</th>\n",
       "      <td>500.126</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1306.972336</td>\n",
       "      <td>1531.932851</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Time  NodeID  tbDecoded  txRxDistanceTB         posX  posY\n",
       "62545  500.126      34        0.0     1464.395216  1374.509312   NaN\n",
       "62547  500.126      35        0.0     1425.415750  1413.488928   NaN\n",
       "62549  500.126      36        0.0     1386.937657  1451.967177   NaN\n",
       "62551  500.126      37        0.0     1345.814549  1493.090461   NaN\n",
       "62553  500.126      38        0.0     1306.972336  1531.932851   NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54074609218696\n",
      "4949.4423782351005\n"
     ]
    }
   ],
   "source": [
    "print(distance_df[\"posX\"].min())\n",
    "print(distance_df[\"posX\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
