{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non Periodic Issues\n",
    "\n",
    "The goal of this jupyter notebook is to find a good example of what I think is occuring. \n",
    "\n",
    "i.e. When we break grants a lot then we keep being pushed into selecting the same resource as others select which is a bad thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import t\n",
    "import multiprocessing\n",
    "import natsort\n",
    "\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON file containing the results for this simulation run\n",
    "results_file = \"/Users/brianmccarthy/git_repos/results-analysis/configs/cv2x.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_folder = \"../data/figures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_file) as results_json:\n",
    "    config = json.load(results_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markers to use for this run\n",
    "markers = [\".\", \"o\", \"v\", \"^\", \"<\", \">\", \"1\", \"2\", \"3\", \"4\", \"8\", \"s\", \"p\", \"P\", \"*\", \"h\",\n",
    "           \"H\", \"+\", \"x\", \"X\", \"D\", \"d\", \"|\", \"_\", 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New results generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_results(results, now):\n",
    "\n",
    "    num_processes = 5\n",
    "    if num_processes > multiprocessing.cpu_count():\n",
    "        print(\"Too many processes, going to revert to total - 1\")\n",
    "        num_processes = multiprocessing.cpu_count() - 1\n",
    "\n",
    "    processed_results = []\n",
    "    for folder in results:\n",
    "        config_name = folder.split(\"/\")[-1]\n",
    "        print(\"Results for config: {}\".format(config_name))\n",
    "        folder_results = []\n",
    "        files = natsort.natsorted(os.listdir(folder))\n",
    "\n",
    "        for i in range(len(files)):\n",
    "            files[i] = \"{}/{}\".format(folder, files[i])\n",
    "\n",
    "        i = 0\n",
    "        while i < len(files):\n",
    "            if len(files) < num_processes:\n",
    "                num_processes = len(files)\n",
    "            pool = multiprocessing.Pool(processes=num_processes)\n",
    "\n",
    "            folder_results.append(pool.starmap(generate_results, zip(files[i: i+num_processes])))\n",
    "\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "\n",
    "            i += num_processes\n",
    "\n",
    "        folder_results = [y for x in folder_results for y in x]\n",
    "        # Go through each of the available stats and write them out to a csv file.\n",
    "        output_csv_dir = \"{}/data/processed_data/{}/{}-{}\".format(os.getcwd(), \"cv2x\",\n",
    "                                                                  config_name, now)\n",
    "        os.makedirs(output_csv_dir, exist_ok=True)\n",
    "\n",
    "        # Shortcut ensures we get the stats from the parsed results\n",
    "        for stat in folder_results[0]:\n",
    "            if \"SCI\" in stat:\n",
    "                across_run_results(folder_results, stat, output_csv_dir, \"txRxDistanceSCI\")\n",
    "            elif stat == \"CBR\":\n",
    "                across_run_results(folder_results, stat, output_csv_dir, \"Time\")\n",
    "            else:\n",
    "                across_run_results(folder_results, stat, output_csv_dir, \"txRxDistanceTB\")\n",
    "\n",
    "        processed_results.append(output_csv_dir)\n",
    "    return processed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(output_csv):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    pdr_sci_agg = pd.DataFrame()\n",
    "    pdr_tb_agg = pd.DataFrame()\n",
    "    ipg_agg = pd.DataFrame()\n",
    "    cbr_agg = pd.DataFrame()\n",
    "\n",
    "    for chunk in pd.read_csv(output_csv, chunksize=10 ** 6):\n",
    "\n",
    "        # SCI PDR calculation\n",
    "        pdr_sci_agg = stat_distance(pdr_sci_agg, chunk, \"sciDecoded\", \"txRxDistanceSCI\", True)\n",
    "\n",
    "        # TB PDR calculation\n",
    "        pdr_tb_agg = stat_distance(pdr_tb_agg, chunk, \"tbDecoded\", \"txRxDistanceTB\", True)\n",
    "\n",
    "        # IPG calculation\n",
    "        ipg_agg = stat_distance(ipg_agg, chunk, \"interPacketDelay\", \"txRxDistanceTB\", False)\n",
    "\n",
    "        # CBR calculation doesn't aggregate the same way as the above so dealt with separately\n",
    "        cbr_df = chunk[chunk[\"cbr\"].notnull()]\n",
    "        cbr_df = cbr_df[[\"Time\", \"cbr\"]]\n",
    "        cbr_df = cbr_df.groupby(\"Time\").agg({\"cbr\": [np.mean, np.std, \"count\"]})\n",
    "        cbr_df.columns = cbr_df.columns.droplevel()\n",
    "        cbr_df = cbr_df.apply(lambda x: x * 100, axis=1)\n",
    "\n",
    "        if cbr_agg.empty:\n",
    "            cbr_agg = cbr_df\n",
    "        else:\n",
    "            # combine_chunks\n",
    "            cbr_agg = cbr_agg.append(cbr_df)\n",
    "\n",
    "    results[\"PDR-SCI\"] = pdr_sci_agg\n",
    "    results[\"PDR-TB\"] = pdr_tb_agg\n",
    "    results[\"IPG\"] = ipg_agg\n",
    "    results[\"CBR\"] = cbr_agg\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_distance(agg_df, df, stat, distance, percentage):\n",
    "\n",
    "    # Reduce the size of the DF to what we're interested in.\n",
    "    distance_df = df[df[stat].notnull()]\n",
    "    distance_df = distance_df[[\"Time\", \"NodeID\", stat, distance]]\n",
    "    distance_df = distance_df[distance_df[stat] > -1]\n",
    "\n",
    "    max_distance = distance_df[distance].max()\n",
    "\n",
    "    # Get the mean, std, count for each distance\n",
    "    distance_df = distance_df.groupby(\n",
    "        pd.cut(distance_df[distance], np.arange(0, max_distance, 10))).agg(\n",
    "        {stat: [np.mean, \"count\"]})\n",
    "\n",
    "    # Remove over head column\n",
    "    distance_df.columns = distance_df.columns.droplevel()\n",
    "    \n",
    "    if percentage:\n",
    "        distance_df = distance_df.apply(lambda x: x * 100, axis=1)\n",
    "\n",
    "    if agg_df.empty:\n",
    "        agg_df = distance_df\n",
    "    else:\n",
    "        # combine_chunks\n",
    "        agg_df = pd.merge(agg_df, distance_df, on=distance, how='outer')\n",
    "        agg_df = agg_df.apply(combine_line, axis=1, result_type='expand')\n",
    "        agg_df = agg_df.rename({0: \"mean\", 1: \"count\"}, axis='columns')\n",
    "    \n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_line(line):\n",
    "    mean_a = line[\"mean_x\"]\n",
    "#     std_a = line[\"std_x\"]\n",
    "    count_a = line[\"count_x\"]\n",
    "\n",
    "    mean_b = line[\"mean_y\"]\n",
    "#     std_b = line[\"std_y\"]\n",
    "    count_b = line[\"count_y\"]\n",
    "    \n",
    "    if np.isnan(mean_a) and np.isnan(mean_b):\n",
    "        return [mean_a, count_a]\n",
    "    elif np.isnan(mean_a) and not np.isnan(mean_b):\n",
    "        return [mean_b, count_b]\n",
    "    elif np.isnan(mean_b) and not np.isnan(mean_a):\n",
    "        return [mean_a, count_a]\n",
    "    else:\n",
    "        ex_a = mean_a * count_a\n",
    "        ex_b = mean_b * count_b\n",
    "#         ex_squared_a = ((std_a ** 2) * (count_a - 1)) + ((ex_a ** 2) / count_a)\n",
    "#         ex_squared_b = ((std_b ** 2) * (count_b - 1)) + ((ex_b ** 2) / count_b)\n",
    "\n",
    "        tx = ex_a + ex_b\n",
    "#         txx = ex_squared_a + ex_squared_b\n",
    "        tn = count_a + count_b\n",
    "\n",
    "        overall_mean = tx / tn\n",
    "#         overall_std = math.sqrt((((txx - tx) ** 2) / tn) / (tn - 1))\n",
    "        overall_count = tn\n",
    "\n",
    "        return [overall_mean, overall_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def across_run_results(results, stat, output_csv_dir, merge_col):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(results)):\n",
    "        if df.empty:\n",
    "            df = results[i][stat]\n",
    "        else:\n",
    "            df = pd.merge(df, results[i][stat], how='outer', on=merge_col,\n",
    "                          suffixes=(i, i + 1), copy=True, indicator=False)\n",
    "\n",
    "    mean_cols = df.filter(regex='mean').columns\n",
    "\n",
    "    n = len(mean_cols) - 1\n",
    "    t_value = t.ppf(.95, n)\n",
    "\n",
    "    df = df.apply(combine_runs, axis=1, result_type='expand', args=(mean_cols, t_value,))\n",
    "    df = df.rename({0: \"Mean\", 1: \"Confidence-Interval\"}, axis='columns')\n",
    "    df.to_csv(\"{}/{}.csv\".format(output_csv_dir, stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_runs(line, mean_cols, t_value):\n",
    "    means = []\n",
    "    for mean in mean_cols:\n",
    "        if np.isnan(line[mean]):\n",
    "            print(\"Mean was nan\")\n",
    "            means.append(0)\n",
    "        else:\n",
    "            means.append(line[mean])\n",
    "\n",
    "    n = len(means)\n",
    "\n",
    "    # Average Across runs\n",
    "    xBar = sum(means) / n\n",
    "\n",
    "    # Deviation between runs and average\n",
    "    deviation = []\n",
    "    for mean in means:\n",
    "        deviation.append((mean - xBar) ** 2)\n",
    "    s2 = sum(deviation) / (n - 1)\n",
    "\n",
    "    # Confidence interval\n",
    "    ci = t_value * math.sqrt(s2 / n)\n",
    "\n",
    "    return [xBar, ci]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdr_graph(folders, graph, comparison, configurations):\n",
    "    pdrs = []\n",
    "    cis = []\n",
    "    distances = []\n",
    "    for folder, config in zip(folders, configurations):\n",
    "        df = pd.read_csv(\"{}/{}.csv\".format(folder, graph))\n",
    "        pdrs.append(list(df[\"Mean\"]))\n",
    "        cis.append(list(df[\"Confidence-Interval\"]))\n",
    "        distances = (list(range(0, df.shape[0] * 10, 10)))\n",
    "        \n",
    "    pdr_dist(pdrs, distances, configurations, \"{}-{}\".format(graph, comparison), confidence_intervals=cis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipg_graph(folders, graph, comparison, configurations):\n",
    "    ipgs = []\n",
    "    cis = []\n",
    "    distances = []\n",
    "    for folder, config in zip(folders, configurations):\n",
    "        df = pd.read_csv(\"{}/{}.csv\".format(folder, graph))\n",
    "        ipgs.append(list(df[\"Mean\"]))\n",
    "        cis.append(list(df[\"Confidence-Interval\"]))\n",
    "        distances = (list(range(0, df.shape[0] * 10, 10)))\n",
    "        \n",
    "    ipg_dist(ipgs, distances, configurations, \"{}-{}\".format(graph, comparison), confidence_intervals=cis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbr_graph(folders, comparison, graph, configurations):\n",
    "    times = []\n",
    "    cbr = []\n",
    "    cis = []\n",
    "    for folder, config in zip(folders, configurations):\n",
    "        df = pd.read_csv(\"{}/CBR.csv\".format(folder))\n",
    "        times.append(list(df[\"Time\"]))\n",
    "        cbr.append(list(df[\"Mean\"]))\n",
    "#         cis.append(list(df[\"Confidence-Interval\"]))\n",
    "        \n",
    "    cbr_plot(cbr, times, \"{}-{}\".format(graph, comparison), configurations, confidence_intervals=cis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for config: After-5-high-density\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/brianmccarthy/git_repos/results-analysis/data/parsed_data/cv2x/After-5-high-density'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3cf8a0a20807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m ]\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprocessed_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_folders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"12:00:00\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-3734cf223450>\u001b[0m in \u001b[0;36mprepare_results\u001b[0;34m(results, now)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results for config: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mfolder_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnatsort\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnatsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/brianmccarthy/git_repos/results-analysis/data/parsed_data/cv2x/After-5-high-density'"
     ]
    }
   ],
   "source": [
    "results_folders = [\n",
    "    \"/Users/brianmccarthy/git_repos/results-analysis/data/parsed_data/cv2x/After-5-high-density\",\n",
    "    \"/Users/brianmccarthy/git_repos/results-analysis/data/parsed_data/cv2x/DCC-Enabled\",\n",
    "    \"/Users/brianmccarthy/git_repos/results-analysis/data/parsed_data/cv2x/NO-CC\",\n",
    "    \"/Users/brianmccarthy/git_repos/results-analysis/data/parsed_data/cv2x/After-1\",\n",
    "    \"/Users/brianmccarthy/git_repos/results-analysis/data/parsed_data/cv2x/After-1-high-density\",\n",
    "    \"/Users/brianmccarthy/git_repos/results-analysis/data/parsed_data/cv2x/NO-CC-high-density\",\n",
    "    \"/Users/brianmccarthy/git_repos/results-analysis/data/parsed_data/cv2x/Highway-fast\",\n",
    "    \"/Users/brianmccarthy/git_repos/results-analysis/data/parsed_data/cv2x/After-5\",\n",
    "    \"/Users/brianmccarthy/git_repos/results-analysis/data/parsed_data/cv2x/Random-Access-Medium-Density\",\n",
    "    \"/Users/brianmccarthy/git_repos/results-analysis/data/parsed_data/cv2x/Random-Access-Packet-Dropping-Medium-Density\",\n",
    "    \"/Users/brianmccarthy/git_repos/results-analysis/data/parsed_data/cv2x/RRI-Adaptation-CR-limit-MD\",\n",
    "    \"/Users/brianmccarthy/git_repos/results-analysis/data/parsed_data/cv2x/RRI-Adaptation-DCC-MD\"\n",
    "]\n",
    "\n",
    "processed_results = prepare_results(results_folders, \"12:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'compare'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7f54c5fc444a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcomparison\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cv2x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compare\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#     print(comparison)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfolders_for_comparison\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mconfigurations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mconfiguration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cv2x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compare\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomparison\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'compare'"
     ]
    }
   ],
   "source": [
    "for comparison in config[\"cv2x\"][\"results\"][\"compare\"]:\n",
    "#     print(comparison)\n",
    "    folders_for_comparison = []\n",
    "    configurations = []\n",
    "    for configuration in config[\"cv2x\"][\"results\"][\"compare\"][comparison]:\n",
    "        for folder in folders:\n",
    "            if configuration in folder:\n",
    "                folders_for_comparison.append(folder)\n",
    "                configurations.append(configuration)\n",
    "                \n",
    "#     print(\"Folders for comparison: {}\".format(folders_for_comparison))\n",
    "    for graph in config[\"cv2x\"][\"results\"][\"graphs\"]:\n",
    "#         print(\"Comparison: {} Graph: {}\".format(comparison, graph))\n",
    "        if graph == \"PDR-SCI\":\n",
    "            pdr_graph(folders_for_comparison, graph, comparison, configurations)\n",
    "        elif graph == \"PDR-TB\":\n",
    "            pdr_graph(folders_for_comparison, graph, comparison, configurations)\n",
    "        elif graph == \"IPG\":\n",
    "            ipg_graph(folders_for_comparison, graph, comparison, configurations)\n",
    "        elif graph == \"CBR\":\n",
    "            cbr_graph(folders_for_comparison, graph, comparison, configurations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_selection(raw_data_folder):    \n",
    "    files = os.listdir(raw_data_folder)\n",
    "    count = 0\n",
    "    file = \"\"\n",
    "    while \".csv\" not in file and count < len(files) * 10:\n",
    "        file = random.choice(files)\n",
    "        count += 1\n",
    "\n",
    "    result_file = raw_data_folder + \"/\" + file\n",
    "    print(\"Random result file selected: {} in {} selections\".format(result_file, count))\n",
    "    random_df = pd.read_csv(result_file)\n",
    "\n",
    "    # Reduce to the time we want which is from 502 onwards.\n",
    "    random_df = random_df[random_df[\"Time\"] >= 502]\n",
    "\n",
    "    node = np.random.choice(random_df[\"NodeID\"].unique(), 1)[0]\n",
    "#     print(\"Node: {}\".format(node))\n",
    "    \n",
    "    return random_df, node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBR individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cbr(dfs, labels, plot_name):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for i in range(len(dfs)):\n",
    "        df = dfs[i]\n",
    "        ax.plot(df[\"Time\"], df[\"cbr\"], label=labels[i])\n",
    "\n",
    "    ax.set(xlabel='Time (s)', ylabel='Channel Busy Ratio %')\n",
    "    ax.legend(loc='lower left')\n",
    "    ax.tick_params(direction='in')\n",
    "\n",
    "    ax.set_ylim([0, 1])\n",
    "    plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "\n",
    "    ax.set_xlim([min(df[\"Time\"]), (max(df[\"Time\"]))])\n",
    "    plt.xticks(np.arange(min(df[\"Time\"]), (max(df[\"Time\"]) + 1), step=1))\n",
    "\n",
    "    plt.savefig(\"{}/{}.png\".format(figure_folder, plot_name), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/brianmccarthy/git_repos/results-analysis/data/raw_data/cv2x/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bfa65e5977a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mselected_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minterested_folders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mresult_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/brianmccarthy/git_repos/results-analysis/data/raw_data/cv2x/'"
     ]
    }
   ],
   "source": [
    "folder_path = \"/Users/brianmccarthy/git_repos/results-analysis/data/raw_data/cv2x/\"\n",
    "interested_folders = [\"NO-CC\", \"DCC-Enabled\", \"After-1\", \"After-5\", \"Highway-fast\", \"NO-CC-high-density\", \"After-1-high-density\", \"After-5-high-density\"]\n",
    "dfs = {}\n",
    "selected_node = False\n",
    "for folder in os.listdir(folder_path):\n",
    "    if folder in interested_folders:\n",
    "        result_path = folder_path + folder\n",
    "        random_df, node = random_selection(result_path)\n",
    "        if not selected_node:\n",
    "            selected_node = node\n",
    "            print(\"Selected Node: {}\".format(selected_node))\n",
    "        random_df = random_df[(random_df[\"NodeID\"] == selected_node) & (random_df[\"cbr\"].notnull())]\n",
    "        dfs[folder] = random_df[[\"Time\", \"cbr\"]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Highway-fast'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-fbdfd4b4f1d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmotivational_cbr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmotivational_cbr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Highway-fast\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmotivational_cbr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"NO-CC\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmotivational_cbr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"NO-CC-high-density\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Highway-fast'"
     ]
    }
   ],
   "source": [
    "motivational_cbr = []\n",
    "motivational_cbr.append(dfs[\"Highway-fast\"])\n",
    "motivational_cbr.append(dfs[\"NO-CC\"])\n",
    "motivational_cbr.append(dfs[\"NO-CC-high-density\"])\n",
    "\n",
    "cbr_medium = []\n",
    "cbr_medium.append(dfs[\"DCC-Enabled\"])\n",
    "cbr_medium.append(dfs[\"NO-CC\"])\n",
    "cbr_medium.append(dfs[\"After-1\"])\n",
    "cbr_medium.append(dfs[\"After-5\"])\n",
    "\n",
    "cbr_high = []\n",
    "cbr_high.append(dfs[\"DCC-Enabled\"])\n",
    "cbr_high.append(dfs[\"NO-CC-high-density\"])\n",
    "cbr_high.append(dfs[\"After-1-high-density\"])\n",
    "cbr_high.append(dfs[\"After-5-high-density\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'df' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-86b4e21b4727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_cbr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotivational_cbr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Highway Fast\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Medium Density\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"High Density\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"motivationalCBR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-2a9e1fe7adde>\u001b[0m in \u001b[0;36mplot_cbr\u001b[0;34m(dfs, labels, plot_name)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'df' referenced before assignment"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cbr(motivational_cbr, [\"Highway Fast\", \"Medium Density\", \"High Density\"], \"motivationalCBR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cbr_medium' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-815fe167e3c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_cbr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbr_medium\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"DCC Access\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No Congestion Control\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"3GPP DCC Mechanism (CBR) - Immediate new grant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"3GPP DCC Mechanism (CBR) - 5 missed trans b4 new grant\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"medium-CBR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cbr_medium' is not defined"
     ]
    }
   ],
   "source": [
    "plot_cbr(cbr_medium, [\"DCC Access\", \"No Congestion Control\", \"3GPP DCC Mechanism (CBR) - Immediate new grant\", \"3GPP DCC Mechanism (CBR) - 5 missed trans b4 new grant\"], \"medium-CBR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cbr_high' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-66aa510177d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_cbr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbr_high\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"DCC Access\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No Congestion Control\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"3GPP DCC Mechanism (CBR) - Immediate new grant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"3GPP DCC Mechanism (CBR) - 5 missed trans b4 new grant\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"high-CBR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cbr_high' is not defined"
     ]
    }
   ],
   "source": [
    "plot_cbr(cbr_high, [\"DCC Access\", \"No Congestion Control\", \"3GPP DCC Mechanism (CBR) - Immediate new grant\", \"3GPP DCC Mechanism (CBR) - 5 missed trans b4 new grant\"], \"high-CBR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collisions issue\n",
    "\n",
    "Section includes code to generate the collision causes and what happens when a grant is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder = \"/Users/brianmccarthy/git_repos/results-analysis/data/raw_data/cv2x/DCC-Enabled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_selection_grant(raw_data_folder):    \n",
    "    files = os.listdir(raw_data_folder)\n",
    "    count = 0\n",
    "    file = \"\"\n",
    "    while \".csv\" not in file and count < len(files) * 10:\n",
    "        file = random.choice(files)\n",
    "        count += 1\n",
    "\n",
    "    result_file = raw_data_folder + \"/\" + file\n",
    "    print(\"Random result file selected: {} in {} selections\".format(result_file, count))\n",
    "    random_df = pd.read_csv(result_file)\n",
    "\n",
    "    # Reduce to the time we want which is from 502 onwards.\n",
    "    random_df = random_df[random_df[\"Time\"] >= 502]\n",
    "\n",
    "    node = np.random.choice(random_df[\"NodeID\"].unique(), 1)[0]\n",
    "    print(\"Node: {}\".format(node))\n",
    "    subsection_df = random_df[random_df[\"NodeID\"] == node]\n",
    "    grant_time = np.random.choice(subsection_df[\"grantStartTime\"].unique(), 1)[0]\n",
    "    selectedSubchannel = subsection_df[subsection_df[\"grantStartTime\"] == grant_time][\"selectedSubchannelIndex\"]\n",
    "    selectedSubchannel = selectedSubchannel.get_values()[0]\n",
    "    print(\"Grant Time: {}, subchannel: {}\".format(grant_time, selectedSubchannel))\n",
    "    generated_time = subsection_df[subsection_df[\"grantStartTime\"] == grant_time][\"Time\"]\n",
    "    generated_time = generated_time.get_values()[0]\n",
    "    print(\"Time of generation: {}\".format(generated_time))\n",
    "    history_time = generated_time - 0.1\n",
    "    print(\"Minimum history time: {}\".format(history_time))\n",
    "    future_time = generated_time + 0.1\n",
    "    print(\"Maximum Future grant time: {}\".format(future_time))\n",
    "    \n",
    "    return random_df, node, generated_time, grant_time, selectedSubchannel, history_time, future_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/brianmccarthy/git_repos/results-analysis/data/raw_data/cv2x/DCC-Enabled'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-9413bd886ff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrant_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_selection_grant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-8d87b97a338b>\u001b[0m in \u001b[0;36mrandom_selection_grant\u001b[0;34m(raw_data_folder)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrandom_selection_grant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m\".csv\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/brianmccarthy/git_repos/results-analysis/data/raw_data/cv2x/DCC-Enabled'"
     ]
    }
   ],
   "source": [
    "df, node, generated_time, grant_time, subchannel, history_time, future_time = random_selection_grant(raw_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c77fc224a880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"grantBreakMissedTrans\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"grantBreakMissedTrans\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-97f8697a2ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"grantBreak\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"grantBreak\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-d5759923d85d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"grantBreakSize\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"grantBreakSize\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d69884407ce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"grantStartTime\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"grantStartTime\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grant_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-409aa7903f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubframeIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrant_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgenerated_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'grant_time' is not defined"
     ]
    }
   ],
   "source": [
    "subframeIndex = int((grant_time - generated_time)* 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-9fd351247126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mhistory_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mfuture_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = df[(df[\"Time\"] >= history_time) & (df[\"Time\"] <= future_time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-dc7cd8b4252b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_removed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generatedGrants\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"grantBreak\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tbSent\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tbFailedDueToProp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tbFailedDueToInterference\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"missedTransmission\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"grantStartTime\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"grantBreakSize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"grantBreakMissedTrans\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sciFailedDueToInterference\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sciFailedDueToProp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"subchannelSent\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"subchannelsUsedToSend\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"selectedSubchannelIndex\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"selectedNumSubchannels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"subchannelsUsed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sciSent\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_removed = df.drop([\"generatedGrants\", \"grantBreak\", \"tbSent\", \"tbFailedDueToProp\", \"tbFailedDueToInterference\", \"missedTransmission\", \"grantStartTime\", \"grantBreakSize\", \"grantBreakMissedTrans\", \"sciFailedDueToInterference\", \"sciFailedDueToProp\", \"subchannelSent\", \"subchannelsUsedToSend\", \"selectedSubchannelIndex\", \"selectedNumSubchannels\", \"subchannelsUsed\", \"sciSent\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_removed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b1b6880ed3b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_removed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_removed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_removed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sciDecoded\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_removed' is not defined"
     ]
    }
   ],
   "source": [
    "df_removed = df_removed[df_removed[\"sciDecoded\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_removed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-787baea92c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"tbDecoded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tbFailedButSCIReceived\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tbFailedDueToNoSCI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tbFailedHalfDuplex\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tbReceived\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"txRxDistanceTB\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf_removed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_removed' is not defined"
     ]
    }
   ],
   "source": [
    "for column in [\"tbDecoded\", \"tbFailedButSCIReceived\", \"tbFailedDueToNoSCI\", \"tbFailedHalfDuplex\", \"tbReceived\", \"txRxDistanceTB\"]:\n",
    "    df_removed[column].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_removed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-9a23eefc3c29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtb_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_removed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cbr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"interPacketDelay\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"posX\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"posY\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"senderID\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"sciDecoded\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"sciFailedHalfDuplex\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"sciNotDecoded\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"sciReceived\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"subchannelReceived\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"txRxDistanceSCI\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msci_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_removed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tbDecoded\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"tbFailedButSCIReceived\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"tbFailedDueToNoSCI\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"tbFailedHalfDuplex\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"tbReceived\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"txRxDistanceTB\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscis_with_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msci_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msci_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"txRxDistanceSCI\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"txRxDistanceTB\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtbs_there\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tbDecoded\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_removed' is not defined"
     ]
    }
   ],
   "source": [
    "tb_df = df_removed.drop([\"cbr\", \"interPacketDelay\", \"posX\", \"posY\", \"senderID\",\"sciDecoded\",\"sciFailedHalfDuplex\",\"sciNotDecoded\",\"sciReceived\",\"subchannelReceived\",\"txRxDistanceSCI\"], axis=1)\n",
    "sci_df = df_removed.drop([\"tbDecoded\",\"tbFailedButSCIReceived\",\"tbFailedDueToNoSCI\",\"tbFailedHalfDuplex\",\"tbReceived\",\"txRxDistanceTB\"], axis=1)\n",
    "\n",
    "scis_with_tb = sci_df[sci_df[\"txRxDistanceSCI\"].isin(tb_df[\"txRxDistanceTB\"].unique())]\n",
    "tbs_there = tb_df[tb_df[\"tbDecoded\"] != -1]\n",
    "\n",
    "scis_without_tb = sci_df[~sci_df[\"txRxDistanceSCI\"].isin(tb_df[\"txRxDistanceTB\"].unique())]\n",
    "tbs_missing = tb_df[tb_df[\"tbDecoded\"] == -1]\n",
    "\n",
    "scis_with_tb = scis_with_tb.merge(tbs_there, left_on=[\"NodeID\", \"Time\", \"txRxDistanceSCI\"], right_on=[\"NodeID\", \"Time\", \"txRxDistanceTB\"])\n",
    "\n",
    "scis_without_tb_merge = scis_without_tb.merge(tbs_missing, how=\"right\", left_on=[\"NodeID\", \"Time\"], right_on=[\"NodeID\", \"Time\"])\n",
    "scis_without_tb_merge = scis_without_tb_merge.drop_duplicates(subset=\"txRxDistanceSCI\")\n",
    "\n",
    "df_removed = scis_without_tb_merge.append(scis_with_tb, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_removed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-2d77d1210484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mafter_grant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbefore_grant_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_removed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_removed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mgenerated_time\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mafter_grant_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_removed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_removed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mgenerated_time\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_removed' is not defined"
     ]
    }
   ],
   "source": [
    "subchannels = 3\n",
    "before_grant = []\n",
    "after_grant = []\n",
    "for i in range(subchannels):\n",
    "    before_grant.append([])\n",
    "    after_grant.append([])\n",
    "    \n",
    "before_grant_df = df_removed[df_removed[\"Time\"] <= generated_time]\n",
    "after_grant_df = df_removed[df_removed[\"Time\"] >= generated_time]\n",
    "\n",
    "# 0 = F\n",
    "# 1 = T\n",
    "time = round(history_time, 3)\n",
    "index = 0\n",
    "while time < generated_time:\n",
    "    # Fill in this subframe\n",
    "    for channel in before_grant:\n",
    "        channel.append(0)\n",
    "    filtered_df = before_grant_df[(before_grant_df[\"Time\"] == time) & (before_grant_df[\"NodeID\"] == node) & (before_grant_df[\"sciDecoded\"] == 1)]\n",
    "    if not filtered_df.empty:\n",
    "        subchs = filtered_df[\"subchannelReceived\"].values\n",
    "        tbDecods = filtered_df[\"tbDecoded\"].values\n",
    "        for i in range(len(tbDecods)):\n",
    "            if tbDecods[i] == 1:\n",
    "                before_grant[int(subchs[i])][index] = 1\n",
    "            elif tbDecods[i] == -1:\n",
    "                before_grant[int(subchs[i][index])] = 2\n",
    "    time = round(time + 0.001, 3)\n",
    "    index += 1\n",
    "\n",
    "# 0 = F -> F\n",
    "# 1 = T -> F\n",
    "# 2 = F -> T\n",
    "# 3 = T -> T\n",
    "# 4 = F -> M\n",
    "# 5 = T -> M\n",
    "# 6 = Selected\n",
    "time = round(generated_time, 3)\n",
    "index = 0\n",
    "while time < future_time:\n",
    "    # Fill in this subframe\n",
    "    for i in range(len(after_grant)):\n",
    "        if before_grant[i][index] == 0:\n",
    "            after_grant[i].append(0)\n",
    "        else:\n",
    "            after_grant[i].append(1)\n",
    "    filtered_df = after_grant_df[(after_grant_df[\"Time\"] == time) & (after_grant_df[\"NodeID\"] == node)]\n",
    "    if not filtered_df.empty:\n",
    "        subchs = filtered_df[\"subchannelReceived\"].values\n",
    "        tbDecods = filtered_df[\"tbDecoded\"].values\n",
    "        for i in range(len(tbDecods)):\n",
    "            if tbDecods[i] == 1 and before_grant[int(subchs[i])][index] == 0:\n",
    "                after_grant[int(subchs[i])][index] = 2\n",
    "            elif tbDecods[i] == 1 and before_grant[int(subchs[i])][index] == 1:\n",
    "                after_grant[int(subchs[i])][index] = 3\n",
    "            elif tbDecods[i] == 1 and before_grant[int(subchs[i])][index] == 2:\n",
    "                after_grant[int(subchs[i])][index] = 4\n",
    "            elif tbDecods[i] == -1 and before_grant[int(subchs[i])][index] == 0:\n",
    "                after_grant[int(subchs[i])][index] = 5\n",
    "            elif tbDecods[i] == -1 and before_grant[int(subchs[i])][index] == 1:\n",
    "                after_grant[int(subchs[i])][index] = 6\n",
    "            elif tbDecods[i] == -1 and before_grant[int(subchs[i])][index] == 2:\n",
    "                after_grant[int(subchs[i])][index] = 7\n",
    "                \n",
    "    if index == subframeIndex:\n",
    "        after_grant[int(subchannel)][index] = 6\n",
    "    time = round(time + 0.001, 3)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'after_grant_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-e153e0d51e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mafter_grant_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mafter_grant_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"NodeID\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m220\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tbDecoded\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'after_grant_df' is not defined"
     ]
    }
   ],
   "source": [
    "after_grant_df[after_grant_df[\"NodeID\"] == 220][\"tbDecoded\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0\n",
      "3 0\n"
     ]
    }
   ],
   "source": [
    "print(len(before_grant), len(before_grant[0]))\n",
    "print(len(after_grant), len(after_grant[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianmccarthy/anaconda3/envs/results-analysis/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Attempting to set identical left == right == -0.5 results in singular transformations; automatically expanding.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAC0CAYAAACDt5wqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAAnElEQVR4nO3c2wmAMAxA0egKpZNk/4k6RNxAxQdFORf6F3qgv4EuEVExoXUGCgZfrrUWmXk4V0+fzKyq2p3511ODwWAwGAwGg8Hg+40x5sC99znwmcBgMBgMBoPBYDAYDAaDwWAwGAwGgz8LW/+AwWAwGAwGg8FgMBgMBoPBYDAYDAa/caktDBgMBoPBYDAYDH6nJXzwBwaDwSfbAPhdLq1J76ogAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2160x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(30, 3))\n",
    "im = ax.imshow(before_grant, interpolation=\"nearest\", cmap=plt.cm.Paired_r)\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(len(before_grant[0]), step=20))\n",
    "ax.set_yticks(np.arange(len(before_grant)))\n",
    "\n",
    "# ax.set_xticklabels(np_xticks)\n",
    "# ax.set_xticklabels(np.array(before_grant)[subframes])\n",
    "\n",
    "for i in range(len(before_grant)):\n",
    "    for j in range(len(before_grant[i])):\n",
    "        if before_grant[i][j] == 1:\n",
    "            text = ax.text(j, i, \"T\", ha=\"center\", va=\"center\", color=\"Black\")\n",
    "        elif before_grant[i][j] == -1:\n",
    "            text = ax.text(j, i, \"M\", ha=\"center\", va=\"center\", color=\"Black\")\n",
    "        else:\n",
    "            text = ax.text(j, i, \"F\", ha=\"center\", va=\"center\", color=\"Black\")\n",
    "\n",
    "plt.gcf().set_facecolor(\"black\")\n",
    "plt.savefig(\"{}/{}.png\".format(figure_folder, \"test_history\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianmccarthy/anaconda3/envs/results-analysis/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: Attempting to set identical left == right == -0.5 results in singular transformations; automatically expanding.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAC0CAYAAACDt5wqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAAnElEQVR4nO3c2wmAMAxA0egKpZNk/4k6RNxAxQdFORf6F3qgv4EuEVExoXUGCgZfrrUWmXk4V0+fzKyq2p3511ODwWAwGAwGg8Hg+40x5sC99znwmcBgMBgMBoPBYDAYDAaDwWAwGAwGgz8LW/+AwWAwGAwGg8FgMBgMBoPBYDAYDAa/caktDBgMBoPBYDAYDH6nJXzwBwaDwSfbAPhdLq1J76ogAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2160x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0 =  F -> F  = F\n",
    "# 1 =  T -> F  = R\n",
    "# 2 =  M -> T  = MT\n",
    "# 3 =  F -> T  = N\n",
    "# 4 =  T -> T  = T\n",
    "# 5 =  F -> M  = NM\n",
    "# 6 =  T -> M  = M\n",
    "# 7 =  M -> M  = MM\n",
    "# 8 = Selected = S\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 3))\n",
    "im = ax.imshow(after_grant, interpolation=\"nearest\", cmap=plt.cm.Paired_r)\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(len(after_grant[0]), step=20))\n",
    "ax.set_yticks(np.arange(len(after_grant)))\n",
    "\n",
    "for i in range(len(after_grant)):\n",
    "    for j in range(len(after_grant[i])):\n",
    "        if after_grant[i][j] == 0:\n",
    "            text = ax.text(j, i, \"F\", ha=\"center\", va=\"center\", color=\"Black\")\n",
    "        elif after_grant[i][j] == 1:\n",
    "            text= ax.text(j, i, \"R\", ha=\"center\", va=\"center\", color=\"Black\")\n",
    "        elif after_grant[i][j] == 2:\n",
    "            text= ax.text(j, i, \"MT\", ha=\"center\", va=\"center\", color=\"Black\")\n",
    "        elif after_grant[i][j] == 3:\n",
    "            text= ax.text(j, i, \"N\", ha=\"center\", va=\"center\", color=\"Black\")\n",
    "        elif after_grant[i][j] == 4:\n",
    "            text= ax.text(j, i, \"N\", ha=\"center\", va=\"center\", color=\"Black\")\n",
    "        elif after_grant[i][j] == 5:\n",
    "            text= ax.text(j, i, \"T\", ha=\"center\", va=\"center\", color=\"Black\")\n",
    "        elif after_grant[i][j] == 6:\n",
    "            text= ax.text(j, i, \"NM\", ha=\"center\", va=\"center\", color=\"Black\")\n",
    "        elif after_grant[i][j] == 7:\n",
    "            text= ax.text(j, i, \"M\", ha=\"center\", va=\"center\", color=\"Black\")\n",
    "        elif after_grant[i][j] == 8:\n",
    "            text= ax.text(j, i, \"MM\", ha=\"center\", va=\"center\", color=\"Black\")\n",
    "        else:\n",
    "            text = ax.text(j, i, \"F\", ha=\"center\", va=\"center\", color=\"Black\")\n",
    "\n",
    "plt.gcf().set_facecolor(\"black\")\n",
    "plt.savefig(\"{}/{}.png\".format(figure_folder, \"test_future\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = .95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/Users/brianmccarthy/git_repos/results-analysis/data/parsed_data/cv2x/\"\n",
    "results = [\n",
    "    \"No Congestion Control\",\n",
    "    \"CR-limit\",\n",
    "    \"DCC\"\n",
    "]\n",
    "\n",
    "less_interesting_results = [\n",
    "    \"High-Density\",\n",
    "    \"Low-Density\",\n",
    "    \"Random-Access\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the information out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_line(line):\n",
    "    mean_a = line[\"sum_x\"]\n",
    "    count_a = line[\"count_x\"]\n",
    "\n",
    "    mean_b = line[\"sum_y\"]\n",
    "    count_b = line[\"count_y\"]\n",
    "\n",
    "    if np.isnan(mean_a) and np.isnan(mean_b):\n",
    "        return [mean_a, count_a]\n",
    "    elif np.isnan(mean_a) and not np.isnan(mean_b):\n",
    "        return [mean_b, count_b]\n",
    "    elif np.isnan(mean_b) and not np.isnan(mean_a):\n",
    "        return [mean_a, count_a]\n",
    "    else:\n",
    "        ex_a = mean_a * count_a\n",
    "        ex_b = mean_b * count_b\n",
    "\n",
    "        tx = ex_a + ex_b\n",
    "        tn = count_a + count_b\n",
    "\n",
    "        overall_mean = tx / tn\n",
    "        overall_count = tn\n",
    "\n",
    "        return [overall_mean, overall_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_runs(line, mean_cols, t_value):\n",
    "    means = []\n",
    "    for mean in mean_cols:\n",
    "        means.append(line[mean])\n",
    "\n",
    "    n = len(means)\n",
    "\n",
    "    # Average Across runs\n",
    "    xBar = sum(means) / n\n",
    "\n",
    "    # Deviation between runs and average\n",
    "    deviation = []\n",
    "    for mean in means:\n",
    "        deviation.append((mean - xBar) ** 2)\n",
    "    s2 = sum(deviation) / (n - 1)\n",
    "\n",
    "    # Confidence interval\n",
    "    ci = t_value * math.sqrt(s2 / n)\n",
    "\n",
    "    return [xBar, ci]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_distance( agg_df, df, stat, distance, percentage):\n",
    "\n",
    "    # Reduce the size of the DF to what we're interested in.\n",
    "    distance_df = df[df[stat].notnull()]\n",
    "    distance_df = distance_df[[\"Time\", \"NodeID\", stat, distance, \"posX\"]]\n",
    "    distance_df = distance_df[distance_df[stat] > -1]\n",
    "    # distance_df = distance_df[(distance_df[\"posX\"] > 1500) & (distance_df[\"posX\"] < 3500)]\n",
    "\n",
    "    # Only interested in max 500m simply as it's not all that relevant to go further.\n",
    "    # Note that going to the max distance of the file can cause issues with how they are parsed.\n",
    "    max_distance = min(510, distance_df[distance].max())\n",
    "\n",
    "    # Get the mean, std, count for each distance\n",
    "    distance_df = distance_df.groupby(\n",
    "        pd.cut(distance_df[distance], np.arange(0, max_distance, 25))).agg(\n",
    "        {stat: [\"sum\", \"count\"]})\n",
    "\n",
    "    # Remove over head column\n",
    "    distance_df.columns = distance_df.columns.droplevel()\n",
    "\n",
    "    if percentage:\n",
    "        distance_df = distance_df.apply(lambda x: x * 100, axis=1)\n",
    "\n",
    "    if agg_df.empty:\n",
    "        agg_df = distance_df\n",
    "    else:\n",
    "        # combine_chunks\n",
    "        agg_df = pd.merge(agg_df, distance_df, on=distance, how='outer')\n",
    "        agg_df = agg_df.apply(combine_line, axis=1, result_type='expand')\n",
    "        agg_df = agg_df.rename({0: \"sum\", 1: \"count\"}, axis='columns')\n",
    "\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****  No Congestion Control  ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianmccarthy/anaconda3/envs/results-analysis/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****  CR-limit  ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianmccarthy/anaconda3/envs/results-analysis/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****  DCC  ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianmccarthy/anaconda3/envs/results-analysis/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "overall_info = {}\n",
    "for result_folder in results:\n",
    "    overall_info[result_folder] = {}\n",
    "    \n",
    "    tb_info = pd.DataFrame()\n",
    "    file_count = 0\n",
    "    grant_info = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        print(\"****  {:}  ****\".format(result_folder))\n",
    "        for file_name in os.listdir(os.path.join(csv_path, result_folder)):\n",
    "            file_path = os.path.join(csv_path, result_folder, file_name)\n",
    "            \n",
    "            agg_df = pd.DataFrame()\n",
    "            grant_df = pd.DataFrame()\n",
    "            file_count += 1\n",
    "            for chunk in pd.read_csv(file_path, chunksize=10 ** 6):\n",
    "                agg_df = stat_distance(agg_df, chunk, \"tbDecoded\", \"txRxDistanceTB\", percentage=False)\n",
    "                \n",
    "                row = []\n",
    "                row.append(chunk[\"grantBreakMissedTrans\"].count())\n",
    "                \n",
    "                grant_df = pd.DataFrame([row], columns=[\"BreakMissedTrans\"])\n",
    "                \n",
    "            if tb_info.empty:\n",
    "                tb_info = agg_df\n",
    "            else:\n",
    "                tb_info = pd.merge(tb_info, agg_df, how='outer', on=\"txRxDistanceTB\",\n",
    "                                   suffixes=(file_count, file_count + 1),\n",
    "                                   copy=True, indicator=False)\n",
    "                \n",
    "            if grant_info.empty:\n",
    "                grant_info = grant_df\n",
    "            else:\n",
    "                grant_info = pd.merge(grant_info, grant_df, how=\"outer\", suffixes=(file_count, file_count +1),\n",
    "                                      copy=True, indicator=False)\n",
    "    \n",
    "        mean_cols = tb_info.filter(regex='sum').columns\n",
    "\n",
    "        n = len(mean_cols) - 1\n",
    "        t_value = t.ppf(p, n)\n",
    "\n",
    "        tb_info = tb_info.apply(combine_runs, axis=1, result_type='expand', args=(mean_cols, t_value,))\n",
    "        tb_info = tb_info.rename({0: \"sum\", 1: \"Confidence-Interval\"}, axis='columns')\n",
    "        \n",
    "        mean_cols = grant_info.filter(regex='BreakMissedTrans').columns\n",
    "\n",
    "        n = len(mean_cols) - 1\n",
    "        t_value = t.ppf(p, n)\n",
    "        \n",
    "        grant_info = grant_info.apply(combine_runs, axis=1, result_type='expand', args=(mean_cols, t_value,))\n",
    "        grant_info = grant_info.rename({0: \"grantBreaks\", 1: \"Confidence-Interval\"}, axis='columns')\n",
    "\n",
    "        overall_info[result_folder][\"tb_info\"] = tb_info\n",
    "        overall_info[result_folder][\"missed_trans\"] = grant_info\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"{} does not contain processed results\".format(result_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute Arrival rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_graph(means, distances, labels, plot_name, ylabel, now, figure_store, legend_pos=\"lower left\",\n",
    "               confidence_intervals=None, show=True, store=False, percentage=False):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for i in range(len(means)):\n",
    "        if confidence_intervals:\n",
    "            ax.errorbar(distances, means[i], yerr=confidence_intervals[i], label=labels[i])\n",
    "        else:\n",
    "            ax.plot(distances, means[i], label=labels[i])\n",
    "\n",
    "    ax.set(xlabel='Distance (m)', ylabel=ylabel)\n",
    "    ax.legend(loc=legend_pos)\n",
    "    ax.tick_params(direction='in')\n",
    "\n",
    "    ax.set_xlim([0, (max(distances) + 1)])\n",
    "    plt.xticks(np.arange(0, (max(distances) + 1), step=50))\n",
    "\n",
    "    if percentage:\n",
    "        ax.set_ylim([0, 100])\n",
    "        plt.yticks(np.arange(0, 101, step=10))\n",
    "\n",
    "    if show:\n",
    "        fig.show()\n",
    "\n",
    "    if store:\n",
    "        fig.savefig(\"{}/{}-{}.png\".format(figure_store, plot_name, now), dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_store = \"../data/figures/\"\n",
    "confidence_intervals = False\n",
    "distances = np.arange(0, 500, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianmccarthy/anaconda3/envs/results-analysis/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "# # DCC + NO-CC\n",
    "# labels = [\"DCC\", \"NO-CC\"]\n",
    "# means = []\n",
    "# cis = []\n",
    "# for key in [\"DCC\", \"No-Congestion-Control\"]:\n",
    "#     means.append(list(overall_info[key][\"tb_info\"][\"sum\"]))\n",
    "\n",
    "#     cis.append(list(overall_info[key][\"tb_info\"][\"Confidence-Interval\"]))\n",
    "        \n",
    "# dist_graph(means, distances, labels, \"DCC-AA\", \"Absolute Arrivals\", \"now\", figure_store, store=True)\n",
    "\n",
    "labels = [\"No Congestion Control\", \"CR-Limit\", \"DCC\"]\n",
    "means = []\n",
    "cis = []\n",
    "for key in [\"No Congestion Control\", \"CR-limit\", \"DCC\"]:\n",
    "    means.append(list(overall_info[key][\"tb_info\"][\"sum\"]))\n",
    "\n",
    "    cis.append(list(overall_info[key][\"tb_info\"][\"Confidence-Interval\"]))\n",
    "        \n",
    "dist_graph(means, distances, labels, \"RRI-Adaptation-long-Absolute-Arrivals\", \"Absolute Arrivals\", \"now\", figure_store, store=True)\n",
    "\n",
    "# labels = [\"No Congestion Control\", \"Packet Dropping no grant break\", \"Packet Dropping Immediate Grant Break\"]\n",
    "# means = []\n",
    "# cis = []\n",
    "# for key in [\"No-Congestion-Control\", \"Packet-Dropping-Grant-Break-After-5-Missed-Trans\", \"Packet-Dropping-Immediate-Grant-Break\"]:\n",
    "#     means.append(list(overall_info[key][\"tb_info\"][\"sum\"]))\n",
    "\n",
    "#     cis.append(list(overall_info[key][\"tb_info\"][\"Confidence-Interval\"]))\n",
    "        \n",
    "# dist_graph(means, distances, labels, \"PacketDropping-AA\", \"Absolute Arrivals\", \"now\", figure_store, store=True)\n",
    "\n",
    "# labels = [\"No Congestion Control\", \"CR-Limit\", \"DCC\"]\n",
    "# means = []\n",
    "# cis = []\n",
    "# for key in [\"No-Congestion-Control\", \"RRI-Adaptation-CR-limit\", \"RRI-Adaptation-DCC-full\"]:\n",
    "#     means.append(list(overall_info[key][\"tb_info\"][\"sum\"]))\n",
    "\n",
    "#     cis.append(list(overall_info[key][\"tb_info\"][\"Confidence-Interval\"]))\n",
    "        \n",
    "# dist_graph(means, distances, labels, \"RRI-Adaptation-AA\", \"Absolute Arrivals\", \"now\", figure_store, store=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misleading grants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"No Congestion Control\", \"CR-Limit\", \"DCC\"]\n",
    "means = []\n",
    "cis = []\n",
    "for key in [\"No Congestion Control\", \"CR-limit\", \"DCC\"]:\n",
    "    means.append(list(overall_info[key][\"missed_trans\"][\"grantBreaks\"]))\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel('Unused Resources')\n",
    "ax.boxplot(means, labels=labels)\n",
    "\n",
    "fig.savefig(\"{}/{}.png\".format(figure_store, \"RRI-Adaptation-long-grantBreaks\"), dpi=300)\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'No-Congestion-Control'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-79b4dcdfca0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"DCC\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No-Congestion-Control\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverall_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"missed_trans\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"grantBreaks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'No-Congestion-Control'"
     ]
    }
   ],
   "source": [
    "# DCC + NO-CC\n",
    "labels = [\"DCC\", \"NO-CC\"]\n",
    "means = []\n",
    "cis = []\n",
    "for key in [\"DCC\", \"No-Congestion-Control\"]:\n",
    "    means.append(list(overall_info[key][\"missed_trans\"][\"grantBreaks\"]))\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel('Unused Resources')\n",
    "ax.boxplot(means, labels=labels)\n",
    "fig.savefig(\"{}/{}.png\".format(figure_store, \"DCC-box-plot\"), dpi=300)\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"No Congestion Control\", \"No grant break\", \"Immediate Grant Break\"]\n",
    "means = []\n",
    "cis = []\n",
    "for key in [\"No-Congestion-Control\", \"Packet-Dropping-Grant-Break-After-5-Missed-Trans\", \"Packet-Dropping-Immediate-Grant-Break\"]:\n",
    "    means.append(list(overall_info[key][\"missed_trans\"][\"grantBreaks\"]))\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel('Unused Resources')\n",
    "ax.boxplot(means, labels=labels)  \n",
    "\n",
    "fig.savefig(\"{}/{}.png\".format(figure_store, \"Packet-Drop-boxplot\"), dpi=300)\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"No Congestion Control\", \"CR-Limit\", \"DCC\"]\n",
    "means = []\n",
    "cis = []\n",
    "for key in [\"No-Congestion-Control\", \"RRI-Adaptation-CR-limit\", \"RRI-Adaptation-DCC-full\"]:\n",
    "    means.append(list(overall_info[key][\"missed_trans\"][\"grantBreaks\"]))\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel('Unused Resources')\n",
    "ax.boxplot(means, labels=labels)\n",
    "\n",
    "fig.savefig(\"{}/{}.png\".format(figure_store, \"Long-RRI-box-plot\"), dpi=300)\n",
    "\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
